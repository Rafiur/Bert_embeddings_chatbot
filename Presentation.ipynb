{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Presentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafiur/Bert_embeddings_chatbot/blob/main/Presentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGO4FRhRKzKp",
        "outputId": "72e1bf97-3f12-4a8b-963f-9419ee08f8d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNYcILVkgAdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138815e2-63d4-4bb8-f13a-32096ae9b9e5"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/37/04e98bf98d055a177d5b4ab342133276011656686743a00dcdf27824a46f/tensorflow_gpu-2.0.0a0-cp37-cp37m-manylinux1_x86_64.whl (332.5MB)\n",
            "\u001b[K     |████████████████████████████████| 332.5MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.12.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.34.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.36.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.4.1)\n",
            "Installing collected packages: keras-applications, tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmMqTnR0kIBL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad222d21-3477-4f5d-ddea-f401649b373f"
      },
      "source": [
        "#@title Install Faiss, TF 2.0, and our Github. Double Click to see code\n",
        "\n",
        "#To use CPU FAISS use\n",
        "!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "#To use GPU FAISS use\n",
        "# !wget  https://anaconda.org/pytorch/faiss-gpu/1.2.1/download/linux-64/faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!pip install mkl\n",
        "\n",
        "#!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install https://github.com/re-search/DocProduct/archive/v0.2.0_dev.zip\n",
        "!pip install gpt2-estimator\n",
        "!pip install pyarrow\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 13:35:13--  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
            "Resolving anaconda.org (anaconda.org)... 104.17.93.24, 104.17.92.24, 2606:4700::6811:5c18, ...\n",
            "Connecting to anaconda.org (anaconda.org)|104.17.93.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9c5c376961204909d87/5aa7f0a65571b411e5c259be?response-content-disposition=attachment%3B%20filename%3D%22faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20210608T133514Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDZG8iqq%2BXIrULgWS3V7IUkVopOrMA4KZdiFJAUkEfT%2BQIgR2pM05%2FvbPTRCkker0c32hY50jvH%2FadmtPg3GV%2BjHcwq%2BgMIdBAAGgw0NTU4NjQwOTgzNzgiDPCftCF5pCScYBEJeCrXA74pdwb3Z5uxvUErJeu71WiaOxzSqV1ohFZ%2BlX2n%2FWFwZ13fp%2FhxZQTRUH6WmlA6bNEMBDSizfFUghysf9ZpyGdIe9CZsz9EZizU0NHsdV%2B5QRZuvMgoKTrXocjlBeY0nv4y6mHvE7Mn97luq%2Bsx345mXpWBebCnBOi3PLEjVoS6xmp5cHUljo0CvivzH2yfv1EUCveDzFNvGOPqbfR0LKVuPxBtew%2Bb1G2Ey8AwjaEWfIpIfm7xlYWp7H%2FVd8nbWuOzTNDXbrsfiBP0fIcP3Dh81MsSCw8SEzyPCC6hrqiT1uR%2B7%2BaHqD%2B25wpwFxhUa2ZF8LXadUI7Usz87mE5%2BCxKuoKdWbcubHtu2gHHjnsCEbbpmI%2F6qaDK%2BVLmMkcwBuWJoB9T6NUe1jCCT1o%2FtleS3R7QvKMvmp5M8v3WmTwqGQQQc38itOM1Q%2FPS%2BbYjMQ3v0ds8azFAKgY2i%2BWg7yh98WBc5BrXx6QP8H4KaUU9je0W7zagdHVv9w6biJS7D5gAU176rkt9ddjxd4jDhS6KvsVwtS1HndcicqtIN8GTpIWEzx9yhxT%2BkDoQtQRtQ1DAaUKhgGaZY4UX4hGzlodmQiSb8JkBnvXPgpLF%2Bt4IliDKHXPTXjDfk%2F2FBjqlAdfiMW59kAUF34RZA9f7XPt9KDXA1TUerxAAuBZ3FRMWgyjDVz2ZdMLfrPXlEY8jExe%2BsB2UprFio%2F9anxVoTLs0aReyQUg3gtjZM%2BJ1KZkc%2FAiuYQYusGabZOHRA54m7Q2xROI7wV%2F7uOkXEUFDWP0QH0WP2RZnRvZSSLTs4at8W%2BxEAi1BVQacZ9bpxssHxWch%2FVm6qxqzg3OB2rBJSBp6RGQa6A%3D%3D&X-Amz-Credential=ASIAWUI46DZFCX7AOAVG%2F20210608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ec453b5f8cb472adbd37b993298ddb36544e1dfcad5a105b39448be84fda65d8 [following]\n",
            "--2021-06-08 13:35:14--  https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9c5c376961204909d87/5aa7f0a65571b411e5c259be?response-content-disposition=attachment%3B%20filename%3D%22faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20210608T133514Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDZG8iqq%2BXIrULgWS3V7IUkVopOrMA4KZdiFJAUkEfT%2BQIgR2pM05%2FvbPTRCkker0c32hY50jvH%2FadmtPg3GV%2BjHcwq%2BgMIdBAAGgw0NTU4NjQwOTgzNzgiDPCftCF5pCScYBEJeCrXA74pdwb3Z5uxvUErJeu71WiaOxzSqV1ohFZ%2BlX2n%2FWFwZ13fp%2FhxZQTRUH6WmlA6bNEMBDSizfFUghysf9ZpyGdIe9CZsz9EZizU0NHsdV%2B5QRZuvMgoKTrXocjlBeY0nv4y6mHvE7Mn97luq%2Bsx345mXpWBebCnBOi3PLEjVoS6xmp5cHUljo0CvivzH2yfv1EUCveDzFNvGOPqbfR0LKVuPxBtew%2Bb1G2Ey8AwjaEWfIpIfm7xlYWp7H%2FVd8nbWuOzTNDXbrsfiBP0fIcP3Dh81MsSCw8SEzyPCC6hrqiT1uR%2B7%2BaHqD%2B25wpwFxhUa2ZF8LXadUI7Usz87mE5%2BCxKuoKdWbcubHtu2gHHjnsCEbbpmI%2F6qaDK%2BVLmMkcwBuWJoB9T6NUe1jCCT1o%2FtleS3R7QvKMvmp5M8v3WmTwqGQQQc38itOM1Q%2FPS%2BbYjMQ3v0ds8azFAKgY2i%2BWg7yh98WBc5BrXx6QP8H4KaUU9je0W7zagdHVv9w6biJS7D5gAU176rkt9ddjxd4jDhS6KvsVwtS1HndcicqtIN8GTpIWEzx9yhxT%2BkDoQtQRtQ1DAaUKhgGaZY4UX4hGzlodmQiSb8JkBnvXPgpLF%2Bt4IliDKHXPTXjDfk%2F2FBjqlAdfiMW59kAUF34RZA9f7XPt9KDXA1TUerxAAuBZ3FRMWgyjDVz2ZdMLfrPXlEY8jExe%2BsB2UprFio%2F9anxVoTLs0aReyQUg3gtjZM%2BJ1KZkc%2FAiuYQYusGabZOHRA54m7Q2xROI7wV%2F7uOkXEUFDWP0QH0WP2RZnRvZSSLTs4at8W%2BxEAi1BVQacZ9bpxssHxWch%2FVm6qxqzg3OB2rBJSBp6RGQa6A%3D%3D&X-Amz-Credential=ASIAWUI46DZFCX7AOAVG%2F20210608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ec453b5f8cb472adbd37b993298ddb36544e1dfcad5a105b39448be84fda65d8\n",
            "Resolving binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)... 52.217.195.193\n",
            "Connecting to binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)|52.217.195.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4106816 (3.9M) [application/x-tar]\n",
            "Saving to: ‘faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2’\n",
            "\n",
            "faiss-cpu-1.2.1-py3 100%[===================>]   3.92M  2.59MB/s    in 1.5s    \n",
            "\n",
            "2021-06-08 13:35:16 (2.59 MB/s) - ‘faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2’ saved [4106816/4106816]\n",
            "\n",
            "info/hash_input.json\n",
            "info/has_prefix\n",
            "info/index.json\n",
            "info/git\n",
            "info/files\n",
            "info/LICENSE.txt\n",
            "info/about.json\n",
            "info/paths.json\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/dependency_links.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/not-zip-safe\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/requires.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/top_level.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/native_libs.txt\n",
            "info/test/run_test.py\n",
            "info/test/run_test.sh\n",
            "info/test/tests/run_tests.sh\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/SOURCES.txt\n",
            "info/recipe/conda_build_config.yaml\n",
            "info/recipe/build.sh\n",
            "info/test/tests/CMakeLists.txt\n",
            "info/test/tests/Makefile\n",
            "info/recipe/meta.yaml.template\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/PKG-INFO\n",
            "info/test/tests/test_factory.py\n",
            "info/test/tests/test_ivfpq_codec.cpp\n",
            "info/recipe/meta.yaml\n",
            "info/recipe/setup.py\n",
            "info/test/tests/test_blas.cpp\n",
            "info/recipe/makefile.inc\n",
            "info/test/tests/test_ivfpq_indexing.cpp\n",
            "info/test/tests/test_ondisk_ivf.cpp\n",
            "info/test/tests/test_build_blocks.py\n",
            "info/test/tests/test_merge.cpp\n",
            "info/test/tests/test_pairs_decoding.cpp\n",
            "info/test/tests/test_index_composite.py\n",
            "lib/python3.6/site-packages/faiss/__init__.py\n",
            "lib/python3.6/site-packages/faiss/__pycache__/__init__.cpython-36.pyc\n",
            "info/test/tests/test_index.py\n",
            "info/test/tests/test_blas\n",
            "lib/python3.6/site-packages/faiss/__pycache__/swigfaiss.cpython-36.pyc\n",
            "lib/python3.6/site-packages/faiss/swigfaiss.py\n",
            "lib/python3.6/site-packages/faiss/_swigfaiss.so\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (2019.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl) (2021.2.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/re-search/DocProduct/archive/v0.2.0_dev.zip\n",
            "\u001b[?25l  Downloading https://github.com/re-search/DocProduct/archive/v0.2.0_dev.zip\n",
            "\u001b[K     - 15.3MB 942kB/s\n",
            "\u001b[?25hCollecting pycurl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/1a/35b1d8b8e4e23a234f1b17a8a40299fd550940b16866c9a1f2d47a04b969/pycurl-7.43.0.6.tar.gz (222kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (3.2.2)\n",
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/4e/402a4d7f21d03cd640b41376727a9ea2bac5a06d2556c04517878dad0c3d/tensorflow-2.0.0a0-cp37-cp37m-manylinux1_x86_64.whl (80.3MB)\n",
            "\u001b[K     |████████████████████████████████| 80.3MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (2.0.0a0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (2.4.3)\n",
            "Collecting keras-pos-embd==0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/56/5e/7b1e933104a25f2039b6788e392a650671e3bcbee6404ea29dcb92295614/keras-pos-embd-0.9.0.tar.gz\n",
            "Collecting keras-transformer==0.21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/3a/ad25f5c71adc6b8aa73f71b1367be873b4103125a614ba57c006d1a9b1ff/keras-transformer-0.21.0.tar.gz\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (4.41.1)\n",
            "Collecting faiss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/2e/dc5697e9ff6f313dcaf3afe5ca39d7d8334114cbabaed069d0026bbc3c61/faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from docproduct==0.2.0) (1.15.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->docproduct==0.2.0) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->docproduct==0.2.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->docproduct==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->docproduct==0.2.0) (0.10.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.14.0a20190301)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (0.8.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (0.36.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0->docproduct==0.2.0) (0.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->docproduct==0.2.0) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->docproduct==0.2.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->docproduct==0.2.0) (3.1.0)\n",
            "Collecting keras-multi-head==0.18.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/5d/8156def9ca75c55bb87819618e9a3e1f8e587c722570e2e93ad616b9269d/keras-multi-head-0.18.0.tar.gz\n",
            "Collecting keras-layer-normalization==0.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/b0/c786d5a5e79d985281a06da0a1f3f559cf425921464e6b07b9f1cb093a5a/keras-layer-normalization-0.11.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/91/21/4eefba0b6ea01de9c6e469970a39dbdbce14e5183a20274d9a181f55eaa8/keras-position-wise-feed-forward-0.4.0.tar.gz\n",
            "Collecting keras-embed-sim==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/16/b05954f9578ded225fd1bd56154ade949782c03b668a1fc424d5050e868a/keras-embed-sim-0.3.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->docproduct==0.2.0) (0.22.2.post1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0->docproduct==0.2.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0->docproduct==0.2.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0->docproduct==0.2.0) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->docproduct==0.2.0) (1.5.2)\n",
            "Collecting keras-self-attention==0.39.0\n",
            "  Downloading https://files.pythonhosted.org/packages/91/70/51150779d5bbd1488a30c62026b141073873faf81eac7a62c6460cb5efe0/keras-self-attention-0.39.0.tar.gz\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->docproduct==0.2.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0->docproduct==0.2.0) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0->docproduct==0.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0->docproduct==0.2.0) (3.4.1)\n",
            "Building wheels for collected packages: docproduct, pycurl, keras-pos-embd, keras-transformer, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for docproduct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docproduct: filename=docproduct-0.2.0-cp37-none-any.whl size=61662 sha256=60c4d7327e7a921092a3e65fd2a8b4c681b354ac1e3937a9f94a8e7e6e2f5f71\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e4332vi2/wheels/d6/ff/7e/7c265da92fd0d24132f65f8f7e28c63c8381f5478c32bd9135\n",
            "  Building wheel for pycurl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycurl: filename=pycurl-7.43.0.6-cp37-cp37m-linux_x86_64.whl size=289416 sha256=923918054636130858334e989f29885fad8e22e405fd383ad358a7ba135ffe1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a1/7b/2894883fd5c69a3ba684a49d255466d1e924b3cf58cedc1ade\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.9.0-cp37-none-any.whl size=6903 sha256=45903e56a11b8214b10292a1638315def10806fcf1987cbd8628701d3f197c23\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/97/65/170068ed0a4bd2185d561afee6c93e23e87e8d735d61389590\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.21.0-cp37-none-any.whl size=10104 sha256=9a5f9cb09e39bccf00831e667516604c560dde0409b9f70eadd47701034d19f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/9f/ff/3b38f44f6db035cfd33cff4909edcc4864a6aeec80d9deaf23\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.18.0-cp37-none-any.whl size=14986 sha256=29b5cdd117a0cba6cf3e6d0307e0c452b87bb40b20736835936c9bdd5f4c592a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/88/83/d7680876b48974c3c11fc334ed1d0a480ae218764062385bf3\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.11.0-cp37-none-any.whl size=4647 sha256=4af28835da51c9161c4b486b04ada0429fc6b63b19c9f5299005b2e2244903f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/dc/2e/3ac54a6b948bff68cb999d210c6ebf9e22df7a4a24cf114436\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.4.0-cp37-none-any.whl size=4654 sha256=232d3626a7571c8ede732c39005972e5ea6c6d36606d054e03c4e9b75551a51e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/a1/13/3c913efde102d56ac584f61004a9fec6f8859b6feec6aa7aa7\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.3.0-cp37-none-any.whl size=3531 sha256=21f3877357e034f4f1d47e233923c2be1a8e9dfbae2777ed96797b2b124d6607\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/f2/c6/0610efe9730c708b24ec29c25cebd38eb485acbc2eee7b5634\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.39.0-cp37-none-any.whl size=17954 sha256=2506765c6d89428b0e6c455c123b4e6ec6fe21cfae4f23b6b317600af10ece3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/d6/3e/cac34bf035198e38947006910f3ecb25613d6d9d76ea6d8ef2\n",
            "Successfully built docproduct pycurl keras-pos-embd keras-transformer keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 2.0.0a0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pycurl, tensorflow, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, faiss, argparse, docproduct\n",
            "Successfully installed argparse-1.4.0 docproduct-0.2.0 faiss-1.5.3 keras-embed-sim-0.3.0 keras-layer-normalization-0.11.0 keras-multi-head-0.18.0 keras-pos-embd-0.9.0 keras-position-wise-feed-forward-0.4.0 keras-self-attention-0.39.0 keras-transformer-0.21.0 pycurl-7.43.0.6 tensorflow-2.0.0a0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt2-estimator\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/78/a83c8f020c7356bb592260fb92f13b5bf6405a31ffe7580f4847436d970a/gpt2_estimator-0.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0a0 in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (2.0.0a0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (2019.12.20)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gpt2-estimator) (1.1.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.34.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (0.4.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (0.36.2)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.14.0a20190301)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0a0->gpt2-estimator) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->gpt2-estimator) (57.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt2-estimator) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt2-estimator) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt2-estimator) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt2-estimator) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gpt2-estimator) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gpt2-estimator) (2.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0a0->gpt2-estimator) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0a0->gpt2-estimator) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==2.0.0a0->gpt2-estimator) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0a0->gpt2-estimator) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0a0->gpt2-estimator) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0a0->gpt2-estimator) (3.7.4.3)\n",
            "Installing collected packages: gpt2-estimator\n",
            "Successfully installed gpt2-estimator-0.1.0\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6LX8KdFp-El"
      },
      "source": [
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "#download_file_from_google_drive(file_id, 'Float16EmbeddingsExpanded5-27-19.pkl')\n",
        "import os\n",
        "import requests\n",
        "\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfN2bCWCmC3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe57c9b-b8d3-448c-8ae6-7138539ffadf"
      },
      "source": [
        "!pip install faiss-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/fe/9b6935d62fc0dd9aff2bd6af3652dc9e0b70e989b6724ebcebdd174db64a/faiss_gpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7MB)\n",
            "\u001b[K     |████████████████████████████████| 89.7MB 104kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyNRn4-Kqh04"
      },
      "source": [
        "#@title Load model weights and Q&A data. Double click to see code\n",
        "\n",
        "from docproduct.predictor import RetreiveQADoc\n",
        "\n",
        "pretrained_path = '/content/gdrive/MyDrive/biobert_v1.0_pubmed_pmc/biobert_v1.0_pubmed_pmc/'\n",
        "# ffn_weight_file = None\n",
        "bert_ffn_weight_file = '/content/gdrive/MyDrive/DocProduct_0.2.0/models/bertffn_crossentropy/bertffn'\n",
        "embedding_file = '/content/gdrive/MyDrive/Float16EmbeddingsExpanded5-27-19.pkl'\n",
        "\n",
        "doc = RetreiveQADoc(pretrained_path=pretrained_path,\n",
        "ffn_weight_file=None,\n",
        "bert_ffn_weight_file=bert_ffn_weight_file, embedding_file=embedding_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rBYU8MENPij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9085ada0-f4de-45f1-c794-d3429b874541"
      },
      "source": [
        "folder_path = '/content/gdrive/MyDrive/Signal_prediction/'\n",
        "from os import listdir\n",
        "flag = True\n",
        "for file_name in listdir(folder_path):\n",
        "  if file_name.endswith('.txt'):\n",
        "    with open(folder_path + file_name) as currentfile:\n",
        "      for line in currentfile:\n",
        "        words = line.split()\n",
        "\n",
        "        if words[0]=='sad':\n",
        "          print('Hey you seem to be sad. What seems to be the matter?')\n",
        "\n",
        "          while flag == True:\n",
        "\n",
        "            user_text = input('User: ')\n",
        "\n",
        "            search_similarity_by = input('Search the similarities in answer or question: ')\n",
        "\n",
        "            number_results_toReturn = input('How many results to return: ')\n",
        "            number_results_toReturn = int(number_results_toReturn)\n",
        "\n",
        "            answer_only = True\n",
        "            returned_results = doc.predict( user_text ,\n",
        "                  search_by=search_similarity_by, topk=number_results_toReturn, answer_only=answer_only)\n",
        "\n",
        "            print('')\n",
        "            for jk in range(len(returned_results)):\n",
        "                print(\"Result \", jk+1)\n",
        "                print(returned_results[jk])\n",
        "                print('')\n",
        "            print('Do you want to continue the conversation?')\n",
        "            user_response = input()\n",
        "            if user_response == 'no':\n",
        "              break\n",
        "        elif words[0]=='upset':\n",
        "\n",
        "          print('You seem upset. Is there something I could help you with?')\n",
        "          \n",
        "          while flag == True:\n",
        "            user_text = input('User: ')\n",
        "          \n",
        "            search_similarity_by = input('Search the similarities in answer or question: ')\n",
        "          \n",
        "            number_results_toReturn = input('How many results to return: ')\n",
        "            number_results_toReturn = int(number_results_toReturn)\n",
        "          \n",
        "            answer_only = True\n",
        "            returned_results = doc.predict( user_text ,\n",
        "                  search_by=search_similarity_by, topk=number_results_toReturn, answer_only=answer_only)\n",
        "\n",
        "            print('')\n",
        "            for jk in range(len(returned_results)):\n",
        "                print(\"Result \", jk+1)\n",
        "                print(returned_results[jk])\n",
        "                print('')\n",
        "            print('Do you want to continue the conversation?')\n",
        "            user_response = input()\n",
        "            if user_response == 'no':\n",
        "              break\n",
        "        elif words[0]=='calm':\n",
        "          print('Hello there! What can I do for you?')\n",
        "          while flag==True:\n",
        "            user_text = input('User: ')\n",
        "\n",
        "            search_similarity_by = input('Search the similarities in answer or question: ')\n",
        "          \n",
        "            number_results_toReturn = input('How many results to return: ')\n",
        "            number_results_toReturn = int(number_results_toReturn)\n",
        "          \n",
        "            answer_only = True\n",
        "            returned_results = doc.predict( user_text ,\n",
        "                  search_by=search_similarity_by, topk=number_results_toReturn, answer_only=answer_only)\n",
        "\n",
        "            print('')\n",
        "            for jk in range(len(returned_results)):\n",
        "                print(\"Result \", jk+1)\n",
        "                print(returned_results[jk])\n",
        "                print('')\n",
        "            print('Do you want to continue the conversation?')\n",
        "            user_response = input()\n",
        "            if user_response == 'no':\n",
        "              break\n",
        "        elif words[0]=='happy':\n",
        "          print('Yohoo! How is it going?')\n",
        "          while flag == True:\n",
        "            user_text = input('User: ')\n",
        "          \n",
        "            search_similarity_by = input('Search the similarities in answer or question: ')\n",
        "          \n",
        "            number_results_toReturn = input('How many results to return: ')\n",
        "            number_results_toReturn = int(number_results_toReturn)\n",
        "          \n",
        "            answer_only = True\n",
        "            returned_results = doc.predict( user_text ,\n",
        "                  search_by=search_similarity_by, topk=number_results_toReturn, answer_only=answer_only)\n",
        "\n",
        "            print('')\n",
        "            for jk in range(len(returned_results)):\n",
        "                print(\"Result \", jk+1)\n",
        "                print(returned_results[jk])\n",
        "                print('')\n",
        "            print('Do you want to continue the conversation?')\n",
        "            user_response = input()\n",
        "            if user_response == 'no':\n",
        "              break\n",
        "        else:\n",
        "          print('Hello. How can I be of service toy ou today?')\n",
        "\n",
        "          while flag == True:\n",
        "            user_text = input('User: ')\n",
        "\n",
        "            search_similarity_by = input('Search the similarities in answer or question: ')\n",
        "\n",
        "            number_results_toReturn = input('How many results to return: ')\n",
        "            number_results_toReturn = int(number_results_toReturn)\n",
        "\n",
        "            answer_only = True\n",
        "            returned_results = doc.predict( user_text ,\n",
        "                  search_by=search_similarity_by, topk=number_results_toReturn, answer_only=answer_only)\n",
        "\n",
        "            print('')\n",
        "            for jk in range(len(returned_results)):\n",
        "                print(\"Result \", jk+1)\n",
        "                print(returned_results[jk])\n",
        "                print('')\n",
        "            print('Do you want to continue the conversation?')\n",
        "            user_response = input()\n",
        "            if user_response == 'no':\n",
        "              break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yohoo! How is it going?\n",
            "User: So, I was wondering if there is a connection between achieving something hard to get and happiness. Yesterday I was promoted and I am in the best mood ever since.\n",
            "Search the similarities in answer or question: answer\n",
            "How many results to return: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  3.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Result  1\n",
            "Let the power of positive thinking help you relax. Here are some affirmations to try:  Let go of things I cannot control. I am healthy, vital, and strong. There is nothing in the world I cannot handle. All my needs are met. I am completely and utterly safe. Every day, in every way, I am getting stronger.\n",
            "\n",
            "Result  2\n",
            "Do you have any structure in your current life like a job or school?  If not, I would add structure like planned exercise, social interaction, and some meaningful goal for the future.  You're constantly distracted by the thing you're trying to deal with, but what is/are those things? Are they important in the bigger picture or just distractions?  It sounds like you have some anxiety, and sometimes inactivity can contribute to that. Are you doing things to make sure you are progressing forward towards a meaningful life? Or just waiting for stuff to happen? Maybe explore new hobbies or find a life coach?,&gt;I recently lost a big piece of the meaning in my life and I am trying to live for myself.\n",
            "\n",
            "Well, what you are going through/feeling may simply be a part of the adjustment and grieving process. Feeling like a burden though is usually a ringer for depression.  You may benefit from a few sessions of counseling to help you sort things out in your head so you can start feeling like yourself again.\n",
            "\n",
            "Do you want to continue the conversation?\n",
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}